{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import rawpy\n",
    "import imageio.v3 as iio\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_exposures(image_paths):\n",
    "    image_paths = [os.path.join(image_paths, f) for f in os.listdir(image_paths) if f.endswith('.tiff')]\n",
    "    images = []\n",
    "    exposures = []\n",
    "    for p in image_paths:\n",
    "        img = Image.open(p).convert('L')  # grayscale\n",
    "        images.append(np.array(img).astype(np.float32))\n",
    "        \n",
    "        exposure = float(p.split('/')[-1].split('.')[0])\n",
    "        exposures.append(1/exposure)\n",
    "    return np.stack(images), np.array(exposures)\n",
    "\n",
    "def load_rgb_images(path):\n",
    "    image_paths = [\n",
    "        os.path.join(path, f)\n",
    "        for f in os.listdir(path) \n",
    "        if f.endswith('.tiff')\n",
    "    ]\n",
    "    exposures = []\n",
    "    images = []\n",
    "    for p in sorted(image_paths):\n",
    "        img = Image.open(p).convert('RGB')\n",
    "        img_np = np.array(img).astype(np.float32)\n",
    "        images.append(img_np)\n",
    "        # If the filename is \"0.1.tiff\", then exposure_time = 0.1\n",
    "        filename = os.path.splitext(os.path.basename(p))[0]\n",
    "        exposure_time = 1/ float(filename)\n",
    "        exposures.append(exposure_time)\n",
    "    images = np.stack(images, axis=0)  # shape (P, H, W, 3)\n",
    "    exposures = np.array(exposures)    # shape (P,)\n",
    "    return images, exposures\n",
    "\n",
    "\n",
    "def sample_pixels(images, num_samples=100):\n",
    "    \"\"\"Randomly sample pixels from image stack (P, H, W) â†’ (N, P)\"\"\"\n",
    "    P, H, W = images.shape\n",
    "    samples = []\n",
    "    for _ in range(num_samples):\n",
    "        x = random.randint(0, W - 1)\n",
    "        y = random.randint(0, H - 1)\n",
    "        samples.append([images[j, y, x] for j in range(P)])\n",
    "    return np.array(samples, dtype=np.float32)\n",
    "\n",
    "def sample_rgb_pixels(images, num_samples=100, min_val=12, max_val=243):\n",
    "    \"\"\"\n",
    "    images:    shape (P, H, W, 3) in range [0..255].\n",
    "    num_samples: how many valid random samples to pick.\n",
    "    min_val:   ignore any pixel < min_val (approx. 5% brightness).\n",
    "    max_val:   ignore any pixel > max_val (approx. 95% brightness).\n",
    "    \"\"\"\n",
    "    P, H, W, C = images.shape\n",
    "    samples_r, samples_g, samples_b = [], [], []\n",
    "    \n",
    "    attempts = 0\n",
    "    max_attempts = 50_000  # limit to avoid infinite loops\n",
    "\n",
    "    while len(samples_r) < num_samples and attempts < max_attempts:\n",
    "        x = random.randint(0, W - 1)\n",
    "        y = random.randint(0, H - 1)\n",
    "        pixel_series = images[:, y, x, :]  # shape (P,3) across P exposures\n",
    "        # Check if ALL exposures for R/G/B are within [min_val, max_val]\n",
    "        if (pixel_series >= min_val).all() and (pixel_series <= max_val).all():\n",
    "            # separate channels\n",
    "            r = pixel_series[:, 0]\n",
    "            g = pixel_series[:, 1]\n",
    "            b = pixel_series[:, 2]\n",
    "            samples_r.append(r)\n",
    "            samples_g.append(g)\n",
    "            samples_b.append(b)\n",
    "        attempts += 1\n",
    "\n",
    "    samples_r = np.array(samples_r, dtype=np.float32)  # (N, P)\n",
    "    samples_g = np.array(samples_g, dtype=np.float32)\n",
    "    samples_b = np.array(samples_b, dtype=np.float32)\n",
    "    return samples_r, samples_g, samples_b\n",
    "\n",
    "\n",
    "def fit_mitsunaga_nayar(samples, times, degree):\n",
    "    \"\"\"\n",
    "    samples: shape (N, P), pixel values in [0,1].\n",
    "    times:   shape (P,), actual exposure times (e.g. 0.1, 0.2, 0.4,...).\n",
    "    degree:  polynomial degree (use smaller to reduce risk of overflow).\n",
    "    Returns: coefficients c (length degree+1).\n",
    "    \"\"\"\n",
    "    N, P = samples.shape\n",
    "    M = degree + 1\n",
    "\n",
    "    A = []\n",
    "    b = []\n",
    "    for j in range(P - 1):\n",
    "        rhs = np.log(times[j]) - np.log(times[j + 1])  # ln(t_j) - ln(t_{j+1})\n",
    "        for i in range(N):\n",
    "            z1 = samples[i, j]\n",
    "            z2 = samples[i, j + 1]\n",
    "            row = [(z1**m - z2**m) for m in range(M)]\n",
    "            A.append(row)\n",
    "            b.append(rhs)\n",
    "\n",
    "    A = np.array(A, dtype=np.float32)\n",
    "    b = np.array(b, dtype=np.float32)\n",
    "\n",
    "    # Solve least squares\n",
    "    c, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "    return c\n",
    "\n",
    "def evaluate_response(z, coeffs):\n",
    "    result = np.zeros_like(z, dtype=np.float32)\n",
    "    for m, c in enumerate(coeffs):\n",
    "        result += c * (z ** m)\n",
    "    return result\n",
    "\n",
    "def update_exposure_ratios(samples, coeffs, degree):\n",
    "    N, P = samples.shape\n",
    "    R_new = []\n",
    "    for j in range(P - 1):\n",
    "        total = 0\n",
    "        for i in range(N):\n",
    "            z1, z2 = samples[i, j], samples[i, j + 1]\n",
    "            fz1 = sum(coeffs[m] * (z1 ** m) for m in range(degree + 1))\n",
    "            fz2 = sum(coeffs[m] * (z2 ** m) for m in range(degree + 1))\n",
    "            if fz2 > 1e-6:\n",
    "                total += fz1 / fz2\n",
    "        R_new.append(total / N)\n",
    "    return R_new\n",
    "\n",
    "\n",
    "def compute_fit_error(samples, coeffs, R, degree):\n",
    "    N, P = samples.shape\n",
    "    error = 0\n",
    "    for i in range(N):\n",
    "        for j in range(P - 1):\n",
    "            z1, z2 = samples[i, j], samples[i, j + 1]\n",
    "            fz1 = sum(coeffs[m] * (z1 ** m) for m in range(degree + 1))\n",
    "            fz2 = sum(coeffs[m] * (z2 ** m) for m in range(degree + 1))\n",
    "            error += (fz1 - R[j] * fz2) ** 2\n",
    "    return error\n",
    "\n",
    "def reconstruct_radiance_rgb(images, times, coeffs_r, coeffs_g, coeffs_b):\n",
    "    \"\"\"\n",
    "    images:  shape (P, H, W, 3), raw images in [0..255]\n",
    "    times:   shape (P,), exposure times\n",
    "    coeffs_: polynomial coefficients for R, G, B\n",
    "    Returns: combined radiance map, shape (H, W, 3).\n",
    "    \"\"\"\n",
    "    P, H, W, _ = images.shape\n",
    "    radiance = np.zeros((H, W, 3), dtype=np.float32)\n",
    "    weight_sum = np.zeros((H, W, 3), dtype=np.float32)\n",
    "\n",
    "    # Convert each image to normalized [0,1]\n",
    "    images_norm = images / 255.0\n",
    "\n",
    "    # We'll clamp exponent to avoid overflow\n",
    "    MAX_EXP = 20.0  # or 25 or 30\n",
    "\n",
    "    for j in range(P):\n",
    "        z = images_norm[j]      # shape (H, W, 3)\n",
    "        ln_t = np.log(times[j]) # log of this exposure time\n",
    "\n",
    "        # Evaluate polynomial for each channel\n",
    "        f_r = evaluate_response(z[..., 0], coeffs_r)\n",
    "        f_g = evaluate_response(z[..., 1], coeffs_g)\n",
    "        f_b = evaluate_response(z[..., 2], coeffs_b)\n",
    "\n",
    "        # exp( g(z) - ln(t) ) = exp( g(z) ) / t\n",
    "        exp_input_r = np.clip(f_r - ln_t, -MAX_EXP, MAX_EXP)\n",
    "        exp_input_g = np.clip(f_g - ln_t, -MAX_EXP, MAX_EXP)\n",
    "        exp_input_b = np.clip(f_b - ln_t, -MAX_EXP, MAX_EXP)\n",
    "\n",
    "        rad_r = np.exp(exp_input_r)\n",
    "        rad_g = np.exp(exp_input_g)\n",
    "        rad_b = np.exp(exp_input_b)\n",
    "\n",
    "        # Weight function (simple \"hat\")\n",
    "        w_r = 1.0 - 2.0 * np.abs(z[..., 0] - 0.5)\n",
    "        w_g = 1.0 - 2.0 * np.abs(z[..., 1] - 0.5)\n",
    "        w_b = 1.0 - 2.0 * np.abs(z[..., 2] - 0.5)\n",
    "\n",
    "        w_r = np.clip(w_r, 0.0, 1.0)\n",
    "        w_g = np.clip(w_g, 0.0, 1.0)\n",
    "        w_b = np.clip(w_b, 0.0, 1.0)\n",
    "\n",
    "        radiance[..., 0] += rad_r * w_r\n",
    "        radiance[..., 1] += rad_g * w_g\n",
    "        radiance[..., 2] += rad_b * w_b\n",
    "\n",
    "        weight_sum[..., 0] += w_r\n",
    "        weight_sum[..., 1] += w_g\n",
    "        weight_sum[..., 2] += w_b\n",
    "\n",
    "    # Avoid divide by zero\n",
    "    mask = (weight_sum < 1e-8)\n",
    "    weight_sum[mask] = 1.0\n",
    "    radiance /= weight_sum\n",
    "\n",
    "    return radiance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_response(z, coeffs):\n",
    "    result = np.zeros_like(z, dtype=np.float32)\n",
    "    for m, c in enumerate(coeffs):\n",
    "        result += c * (z ** m)\n",
    "    return result\n",
    "\n",
    "\n",
    "def tone_map(img, exposure=1e-3, gamma=2.2):\n",
    "    mapped = 1.0 - np.exp(-img * exposure)\n",
    "    mapped = np.clip(mapped, 0, 1)\n",
    "    mapped = mapped ** (1.0 / gamma)\n",
    "    return (mapped * 255).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/raw/\"\n",
    "output_path = \"../data/output/\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# 1) Load images, exposures\n",
    "images, times = load_rgb_images(data_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 300\n",
    "samples_r, samples_g, samples_b = sample_rgb_pixels(images, NUM_SAMPLES)\n",
    "samples_r /= 255.0\n",
    "samples_g /= 255.0\n",
    "samples_b /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 5  # or whatever you like\n",
    "coeffs_r = fit_mitsunaga_nayar(samples_r, times, degree)\n",
    "coeffs_g = fit_mitsunaga_nayar(samples_g, times, degree)\n",
    "coeffs_b = fit_mitsunaga_nayar(samples_b, times, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiance_map = reconstruct_radiance_rgb(\n",
    "    images, \n",
    "    times, \n",
    "    coeffs_r, \n",
    "    coeffs_g, \n",
    "    coeffs_b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDR min: 0.0\n",
      "HDR max: 430.68472\n",
      "HDR mean: 10.129795\n"
     ]
    }
   ],
   "source": [
    "print(\"HDR min:\", radiance_map.min())\n",
    "print(\"HDR max:\", radiance_map.max())\n",
    "print(\"HDR mean:\", radiance_map.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_mapped = tone_map(radiance_map)\n",
    "iio.imwrite(os.path.join(output_path, \"tone_mapped.jpg\"), tone_mapped)\n",
    "\n",
    "# 7) Optionally store HDR as EXR or HDR\n",
    "#    imageio can do EXR (if installed with proper plugin).\n",
    "#    We'll just do 32-bit .hdr for demonstration.\n",
    "radiance_map_normalized = radiance_map / np.max(radiance_map)\n",
    "iio.imwrite(os.path.join(output_path, \"output.hdr\"),\n",
    "            radiance_map_normalized.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying degree 1\n",
      "Degree 1, Error = 189.4541\n",
      "Trying degree 2\n",
      "Degree 2, Error = 413.1399\n",
      "Trying degree 3\n",
      "Degree 3, Error = 91.7379\n",
      "Trying degree 4\n",
      "Degree 4, Error = 78.6007\n",
      "Trying degree 5\n",
      "Degree 5, Error = 80.0019\n",
      "Trying degree 6\n",
      "Degree 6, Error = 53.7064\n",
      "Trying degree 7\n",
      "Degree 7, Error = 7.7069\n",
      "Trying degree 8\n",
      "Degree 8, Error = 101.6240\n",
      "Trying degree 9\n",
      "Degree 9, Error = 655.1189\n",
      "Trying degree 10\n",
      "Degree 10, Error = 518.7669\n",
      "Trying degree 1\n",
      "Degree 1, Error = 334.6911\n",
      "Trying degree 2\n",
      "Degree 2, Error = 144.9165\n",
      "Trying degree 3\n",
      "Degree 3, Error = 78.9072\n",
      "Trying degree 4\n",
      "Degree 4, Error = 100.0462\n",
      "Trying degree 5\n",
      "Degree 5, Error = 52.8848\n",
      "Trying degree 6\n",
      "Degree 6, Error = 37.2322\n",
      "Trying degree 7\n",
      "Degree 7, Error = 32.1803\n",
      "Trying degree 8\n",
      "Degree 8, Error = 66.5373\n",
      "Trying degree 9\n",
      "Degree 9, Error = 10363.7942\n",
      "Trying degree 10\n",
      "Degree 10, Error = 13452.7760\n",
      "Trying degree 1\n",
      "Degree 1, Error = 4.2218\n",
      "Trying degree 2\n",
      "Degree 2, Error = 154.9901\n",
      "Trying degree 3\n",
      "Degree 3, Error = 111.8467\n",
      "Trying degree 4\n",
      "Degree 4, Error = 67.7641\n",
      "Trying degree 5\n",
      "Degree 5, Error = 76.5959\n",
      "Trying degree 6\n",
      "Degree 6, Error = 625.6555\n",
      "Trying degree 7\n",
      "Degree 7, Error = 60.3354\n",
      "Trying degree 8\n",
      "Degree 8, Error = 38.7914\n",
      "Trying degree 9\n",
      "Degree 9, Error = 6849.5251\n",
      "Trying degree 10\n",
      "Degree 10, Error = 554.3125\n"
     ]
    }
   ],
   "source": [
    "samples_rgb = [samples_r, samples_g, samples_b]\n",
    "best_coeffs_rgb = []\n",
    "best_error_rgb = []\n",
    "best_order_rgb = []\n",
    "\n",
    "\n",
    "\n",
    "for samples in samples_rgb:\n",
    "    best_coeffs = None\n",
    "    best_error = float('inf')\n",
    "    best_order = None\n",
    "    for degree in range(1, 8):\n",
    "        print(f\"Trying degree {degree}\")\n",
    "        R = [exposures[j] / exposures[j+1] for j in range(len(exposures) - 1)]\n",
    "        for _ in range(MAX_ITERS):\n",
    "            coeffs = fit_polynomial_response(samples, R, degree)\n",
    "            R = update_exposure_ratios(samples, coeffs, degree)\n",
    "        error = compute_fit_error(samples, coeffs, R, degree)\n",
    "        print(f\"Degree {degree}, Error = {error:.4f}\")\n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_coeffs = coeffs\n",
    "            best_order = degree\n",
    "    best_coeffs_rgb.append(best_coeffs)\n",
    "    best_error_rgb.append(best_error)\n",
    "    best_order_rgb.append(best_order)\n",
    "    \n",
    "best_coeffs_r, best_coeffs_g, best_coeffs_b = best_coeffs_rgb\n",
    "best_error_r, best_error_g, best_error_b = best_error_rgb\n",
    "best_order_r, best_order_g, best_order_b = best_order_rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiance_map = reconstruct_radiance_rgb(images, exposures, best_coeffs_r, best_coeffs_g, best_coeffs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_mapped = tone_map(radiance_map, exposure=1e-4)\n",
    "radiance_map_normalized = radiance_map / np.max(radiance_map)\n",
    "iio.imwrite(os.path.join(output_path, \"tone_mapped.jpg\"), tone_mapped)\n",
    "iio.imwrite(os.path.join(output_path, \"output.hdr\"), radiance_map_normalized.astype(np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
